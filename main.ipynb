{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some utility functions to simplify object-oriented programming in jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class): #@save\n",
    "    \"\"\" Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also utilize another utility class that saved the constructor params when passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "class HyperParameters: #@save\n",
    "    def save_hyperparameters(self, ignore=[]):\n",
    "        frame = inspect.currentframe().f_back\n",
    "        _,_,_, local_vars = inspect.getargvalues(frame)\n",
    "        self.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final utility allows us to plot experiment progress interactively while it is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBoard(HyperParameters): #@save\n",
    "    def __init__(self, xlabel=None, ylabel=None, xlim=None, ylim=None, \n",
    "                 xscale='linear', yscale='linear', ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'],\n",
    "                 fig=None, axes=None, figsize=(3.5, 2.5), display=True):\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def draw(self, x, y, label, every_n=1):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a way to define an abstract represenation of all our machine leanring models.\n",
    "The module class is the base class of all modles we will implement. We need this class to:\n",
    "*   store learnable parameters using the `__init__` method\n",
    "*   the `training_step` method return the loss value\n",
    "*   lastly, a `configure_optimizers` method that returns the optimization method or a list of them that is used to update the learnable parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(torch.nn.Module, HyperParameters):\n",
    "    def __init__(self, plot_train_per_epoch=2, plot_valid_per_epoch=1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.board = ProgressBoard()\n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self, X):\n",
    "        assert hasattr(self, 'net'), 'Neural network is defined' \n",
    "        return self.net(x)\n",
    "    \n",
    "    def plot(self, key, value, train: bool):\n",
    "        \"\"\"Plot a point in animation\"\"\"\n",
    "        assert hasattr(self, 'trainer'), 'Trainer is not defined'\n",
    "        self.board.xlable = 'epoch'\n",
    "        if train:\n",
    "            x = self.trainer.train_batch_idx / \\\n",
    "                self.trainer.num_train_batches\n",
    "            n = self.trainer.num_train_batches / \\\n",
    "                self.plot_train_per_epoch\n",
    "        else:\n",
    "            x = self.trainer.epoch + 1\n",
    "            n = self.trainer.num_val_batches / \\\n",
    "                self.plot_valid_per_epoch\n",
    "        self.board.draw(x, value.to(torch.cpu()).detach().numpy(),\n",
    "                        ('train_' if train else 'val_') + key,\n",
    "                        every_n=int(n))\n",
    "        \n",
    "        def training_step(self, batch):\n",
    "            l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "            self.plot('loss', l, train=False)\n",
    "            return l\n",
    "\n",
    "        def validation_step(self, batch):\n",
    "            l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "            self.plot('loss', l, train=False)\n",
    "\n",
    "        def configure_optimizers(self):\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(HyperParameters):\n",
    "    def __init__(self, root='../data', num_workers=4):\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def get_dataloader(self, train: bool):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(self, True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader(self, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Trainer` class trains the learnable parameters in the Module Class with data specified in DataModule. The key method to this interface is the `fit` method which accepts the model of type `Module` and the data of type `DataModule`. \n",
    "The interface iterates over the entire dataset `max_epochs` times to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(HyperParameters):\n",
    "    def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0):\n",
    "        self.save_hyperparameters()\n",
    "        assert num_gpus == 0, 'No GPU support yet'\n",
    "\n",
    "    def prepare_data(self, data: DataModule) -> None:\n",
    "        self.train_dataloader = data.train_dataloader()\n",
    "        self.val_dataloader = data.val_dataloader()\n",
    "        self.num_train_batches = len(self.train_dataloader)\n",
    "        self.num_val_batches = (len(self.val_dataloader) if self.val_dataloader is not None else 0)\n",
    "\n",
    "    def prepare_model(self, model: Module) -> None:\n",
    "        model.trainer = self\n",
    "        model.board.xlim = [0, self.max_epochs]\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, model: Module, data: DataModule) -> None:\n",
    "        self.prepare_data(data)\n",
    "        self.prepare_model(model)\n",
    "        self.optim = model.configure_optimizers()\n",
    "        self.epoch = 0\n",
    "        self.train_batch_idx = 0\n",
    "        self.val_batch_idx = 0\n",
    "        for self.epoch in range(self.max_epochs):\n",
    "            self.fit_epoch()\n",
    "\n",
    "    def fit_epoch(self):\n",
    "        raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
